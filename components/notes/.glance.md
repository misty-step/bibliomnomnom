### Technical Overview: /components/notes

#### Purpose

This directory contains the core note-taking engine for the application, enabling users to capture, manage, and synthesize reflections on books. It supports three distinct input modalities: manual text entry (Markdown-enabled), optical character recognition (OCR) from photos, and long-form voice "listening sessions" that generate AI-synthesized insights.

#### Architecture and Key File Roles

The architecture follows a modular pattern where high-level orchestrators manage state for specialized input methods, while shared UI components handle display and persistence.

- **Note Management & Display**:
  - `NoteList.tsx`: The primary container that fetches a stream of notes for a specific book using Convex queries and handles empty/loading states.
  - `NoteCard.tsx`: A polymorphic component that renders individual notes or quotes. It manages local edit states, performs Markdown-to-HTML sanitization via `DOMPurify`, and handles update/delete mutations.
  - `NoteTypeSelector.tsx`: A controlled component for toggling between "note" and "quote" schemas.

- **Content Creation**:
  - `CreateNote.tsx`: An expandable entry point that orchestrates the manual note-creation flow, integrating the editor and OCR trigger.
  - `Editor.tsx`: A Tiptap-based rich text wrapper that provides a seamless bridge between HTML (editor state) and Markdown (storage format) using `marked` and `turndown`.

- **Advanced Capture Systems**:
  - `PhotoQuoteCapture.tsx`: Manages a multi-stage OCR pipeline. It handles client-side image transcoding (JPEG compression to meet server limits), manages a camera/file input interface, and interacts with a dedicated `/api/ocr` endpoint to extract text from book pages.
  - `useListeningSessionRecorder.ts`: A complex state machine for audio capture. It orchestrates the `MediaRecorder` API, manages a 30-minute session cap with alert tones, and executes a sequential processing pipeline: audio upload, transcription (Deepgram/ElevenLabs), and AI synthesis.
  - `ListeningSessionRecorder.tsx`: The UI layer for voice sessions, providing live feedback via the browserâ€™s `SpeechRecognition` API and displaying synthesized artifacts (insights, follow-up questions, and context expansions).

#### Key Dependencies

- **Convex**: Powers the real-time data layer and mutations for note persistence.
- **Tiptap (@tiptap/react)**: Used for the underlying editor framework.
- **Marked & Turndown**: Handle bidirectional conversion between Markdown and HTML.
- **DOMPurify**: Ensures safe rendering of parsed Markdown content.
- **PostHog**: Tracks session telemetry, specifically for voice recording events and OCR success rates.

#### Important Gotchas

- **Browser Compatibility**: Live transcription in `useListeningSessionRecorder` relies on `window.SpeechRecognition`, which has inconsistent support across browsers (e.g., limited in some non-Chromium environments); the system falls back to server-side transcription in these cases.
- **OCR Limits**: `PhotoQuoteCapture` enforces strict client-side JPEG transcoding to stay under `MAX_IMAGE_BYTES` before hitting the serverless function endpoint.
- **Markdown Sync**: The `Editor` component uses a `useRef` and `useEffect` pattern to sync external content changes; care must be taken to avoid cursor-jumping loops during bidirectional HTML/Markdown conversion.
- **Voice Session Lifecycle**: Voice sessions are strictly bound to the `bookId` context. Switching books during an active recording triggers an immediate session failure to prevent cross-pollinating book data.
