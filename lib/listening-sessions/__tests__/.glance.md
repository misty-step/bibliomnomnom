This directory contains the unit test suite for the context packing logic within the `listening-sessions` module. Its primary purpose is to validate the algorithm responsible for aggregating, filtering, and prioritizing user data—such as book metadata and reading notes—into a structured format suitable for AI synthesis while adhering to strict token constraints.

### Architecture and Key Roles

The directory focuses on testing the `packContext` function, which serves as a data transformer between the application's raw library state and the input requirements of a Large Language Model (LLM). The tests are structured using **Vitest** and utilize a factory-based pattern (`makeNote`, `makeLibraryBook`, etc.) to generate deterministic mock data for various scenarios.

**Key File Roles:**

- **`contextPacker.test.ts`**: The central test suite. It verifies several critical heuristics of the packing algorithm:
  - **Token Budgeting**: Ensures the output stays within a specified token limit, testing both the dropping of low-priority items and the truncation of oversized content.
  - **Prioritization Logic**: Validates that notes from the "current book" are prioritized over historical notes and that a "diversity cap" is applied to prevent a single book from dominating the context.
  - **Privacy and Redaction**: Confirms that books and notes marked as private are excluded from the context, with the specific exception of the current book's own notes.
  - **Data Normalization**: Checks that whitespace-only content is ignored and that the resulting summary object accurately reflects the packing operations performed.

### Dependencies and Technical Constraints

- **Vitest**: The testing framework used for assertions and test execution.
- **Token Estimation**: The logic relies on a character-to-token ratio (visible in budget tests) to approximate LLM context usage.
- **Deterministic Output**: The tests enforce that the packing algorithm remains deterministic given identical inputs, which is critical for consistent AI behavior.
- **Budget Gotchas**: The suite highlights that book metadata (title and author) is treated as non-negotiable overhead; if the token budget is set to zero, these elements may still be counted in the final usage summary even if all other content is stripped.
